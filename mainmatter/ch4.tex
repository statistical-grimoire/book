%\chapter{The Basics of Loading and Manipulating Data}
\chapter{Taxonomies of the Profane – Variables, Scales, and Their Unholy Properties}

\IMFellEnglish
\lettrine[lines=5, realheight]{W}{hen} we seek to understand a dataset as a thing unto itself, we are engaging in nothing short of an act of necromancy. It is an attempt to give voice to something that is potentially vast, shapeless, and even dead. We cannot see the thing's full form; we are too small, too insignificant, and the catacombs stretch too deep. But we can listen. We can measure its echoes. 

These are not the thing itself, but the traces it leaves in the air as it moves past us. These measures do not reveal the full anatomy of the creature; they offer only its shadow on the wall, its weight in the dust, its shriek retreating into the stone. And yet, rely on them we must. They are how we pretend to understand the whole, even when what we see is only a sliver of the crypt.

\normalfont

\section{A Practical Problem}

Consider the complete craniometric dataset provided by  \textcite{Thomson1905}, available in the file \R{Thomson\_Randall-MacIver\_1905.csv}.\footnote{The data file can be obtained at this book's GitHub repository: \url{https://github.com/statistical-grimoire/book/blob/main/data/Egyptian-skulls}} This file contains a wide range of measurements taken from skulls recovered at various ancient Egyptian archaeological sites. While selected portions of this dataset were previously used in Chapter 3 to demonstrate data manipulation and plotting, we will now be working with the entire dataset. Table \ref{tab:skulls_full} presents a small excerpt—roughly 1/16\textsuperscript{th} of the full data—which includes a variety of craniometric measurements along with useful contextual information, such as the estimated date range for each skull, the ruling dynasty at the time, and the archaeological site of origin.

\input{tables/ch-4/skulls_full}

To simplify a complex situation, let us restrict ourselves to working with the estimated cranial capacity of the skulls—given by the last column, ``cc.'' Loading and subsetting the data, we find that this leaves us with 1,449 measurements to conduct our analyses with.

\begin{inR}
library(tidyverse)
skulls <- read_csv("Thomson_Randall-MacIver_1905.csv")

skulls <- skulls |> 
  select(table:sex, cc) |> # grab relevant columns
  drop_na(cc) # remove rows containing NAs in the `cc` column
  
nrow(skulls)
\end{inR}

\begin{outR}
[1] 1449
\end{outR}

\noindent
However, this raises a couple of important questions:

\begin{enumerate}
    \item What exactly do we mean by ``analyses'' in this context?
    \item Given the sheer number of distinct values—1,449, to be precise—how can we discuss this data in a practical and meaningful way?
\end{enumerate}

Listing all 1,449 values every time we want to reference the dataset would be wildly impractical. And even if we were absurdly committed to doing so, it is safe to say that our meagre primate brains simply are not equipped to juggle that much information at once. What we are after then are clear, compact, and accurate descriptions of the data that still capture its essential features. Put another way, we need to distil the data's chaos into something intelligible. This may seem a hopeless task given the volume of data; however, there is often a surprisingly large amount of order buried within chaos.

\section{Descriptive vs. Inferential Analyses}

The analysis of data is often guided by two principal objectives. The first is \textbf{descriptive}: to summarize the data in mathematical terms that are, ideally, intuitive and meaningful. This is known as \gls{descriptive analysis}. The second is \textbf{inferential}: to use those summaries to draw conclusions that extend beyond the data itself. These inferences are typically assumed to carry some form of practical significance\footnote{While practical significance should be a requirement for any inferential analysis, many analyses are often performed more out of tradition than any genuine purpose. This is not your author being cynical, just speaking jadedly from experience.}—for example, by helping to answer a critical research question. This is known as inferential analysis.

In many respects \textit{descriptive analysis} is should be a purely empirical task. To the best of the analyser's ability, it is about answering the simple question ``what do we know for certain about this data?''  \textit{Inferential analysis}, by contrast, goes a step further by introducing reasonable assumptions that allow us to make predictions or generalizations that the data alone cannot support.

\section{Data}

The word data has appeared frequently throughout this book, often without much reflection as to what it actually means. Given that data is the central subject of both \textit{descriptive} and \textit{inferential} analysis, it is perhaps worth taking a moment to clarify. At its core, \gls{data} refers to a collection of observations about \textit{something}. The singular form, \gls{datum}, refers to just one of those observations. The ``something'' in question is usually the phenomenon the researcher is investigating—this could be the number of cells in a slice of brain tissue, the rate of deaths per capita, how quickly participants learn a behavioural response; or any number of other things that can be measured or classified. 

Before going further, it’s worth drawing a distinction between what we will refer to as \textit{statistical data}—the kind typically used in research and analysis (e.g., see Table \ref{tab:msleep} and Table \ref{tab:skulls_full})—and the data used to train machine learning models (e.g., pictures of cats, playlists of Eurodance hits, or whatever else the algorithm gods demand). In the latter case, what’s being fed to the model often resembles collections of stimuli more than data in the traditional statistical sense of the term. That said, in machine learning contexts, the terms \textit{data} and \textit{stimuli} are often used interchangeably.

\subsection{A Taxonomy of Data - Scales of Measurement}

Each row in Table \ref{tab:skulls_full} corresponds to a single skull examined by \textcite{Thomson1905}. Each column captures a different type of information recorded for that skull. Some columns contain categorical details—such as the ruling dynasty at the time of burial, the archaeological site where the skull was found, or the presumed sex of the individual—while others include numerical measurements, like the glabello-occipital length (gol), ophryo-occipital length (ool), and basi-bregmatic height (bbh), to name just a few.

Each of these columns represents what we call a variable—a characteristic or property that can vary from one observation (i.e., row) to another. More broadly, variables can be either qualitative (descriptive, non-numeric) or quantitative (numerical), and they form the backbone of any dataset used in statistical analysis.

The way you approach descriptive or inferential analysis depends critically on the nature of your variables. For example, it makes little sense to compute the mean of categorical traits like eye colour, biological sex, or whether a plant specimen is alive or dead. Calculating a mean assumes the data possess certain numerical properties—specifically, that the values lie on a scale where arithmetic operations like addition and division are valid. When those conditions are not met, the result is not just meaningless—it is misleading.

Since the late 1940s, data in most areas of science has traditionally been classified into four types, known as \textit{scales of measurement}. This framework arose in response to a philosophical dilemma that emerged as the field of Psychology sought to establish itself as a valid scientific discipline. Specifically, it revolved around a deceptively simple question: \textit{Is it possible to measure human sensation?} \parencite[p. 677]{Stevens1946}.

To see why this question matters, consider a basic example. Suppose you ask participants in a study to rate their happiness on a 11-point scale, where 0 represents the absence of any happiness and 10 represents the happiest they could
conceivably be. For simplicity, imagine you only have two participants—one selects a 3, the other a 5. A common research practice is to compute the mean average, which in this case would be 4. 

\begin{equation}
\frac{3 + 5}{2} = \frac{8}{2} = 4
\end{equation}

But there is a potential problem lurking here: the ``psychological distance'' between numbers on the scale may not be consistent across individuals. What one person considers a 5, another might interpret as a 7, or a 3, or some other value. That becomes an issue when we calculate a mean because the process of adding the values in the numerator assumes these values have a meaning independent of the person. For instance, if instead the participants had reported 2 and 6 we would similarly arrive at 8 in the numerator, but we have no reason to assume that mathematical equality (3 + 5 = 2 + 6 = 8) should hold because the numbers reflect \textit{subjective} judgments, not objective quantities with a standardized unit of measurement. Thus, we cannot be certain that participants are interpreting the numbers in a comparable way. Moreover, there is no means to verify the accuracy or complete truth of any subjective statement of this kind. We have to take it more or less on faith that, not only are they telling the truth, but that they have the ability to accurately report their subjective states. This challenge—often referred to as the problem of introspection—has haunted Psychology since its earliest days under Wilhelm Wundt in the mid-to-late 19th century. 

That said, one must be cautious not to cast all such measures into the inferno. As \textcite{Labovitz1967} argues, there may still be value—however impure—in treating these subjective ratings as more numeric than they truly are. Despite their crude, unstable, and potentially erroneous nature, they may still be sufficiently precise to extract some kind of signal from the noise. Introspection is a murky cauldron to be sure, but pursuing methodological purity risks sacrificing potentially useful data upon an altar of perfectionism, discarding what might yet yield insight merely because it fails to meet some idealized standard.


% Add examples of descriptive and inferential analyses.

%Include section on Random variables?

% \section{Central Tendency and Spread}

% \subsection{Types of Numeric Data}


%https://www.britannica.com/science/sone