%\chapter{The Basics of Loading and Manipulating Data}
\chapter{Taxonomies of the Profane – Variables, Scales, and Their Unholy Properties}

\IMFellEnglish
\lettrine[lines=5, realheight]{T}{HERE} is a kind of grim devilry in the act of classification. The moment you categorize a thing—whether it be a small volume of blood, the reaction time of a startle, or the flickering presence of a belief—you strip it from the chaos of the unknown and chain it down, trembling, to a scale. Statisticians call them variables, but do not be fooled: these are not gentle creatures. They are twisted reflections of reality that must be bound in measurement and tortured into order. Nominal. Ordinal. Interval. Ratio. These are the sigils we etch into our grimoires of data, each one whispering what kind of rituals—summations, correlations, regressions—we may dare perform. But beware: misuse the wrong scale, or confuse the nature of your variable, and the results may turn on you, distorted and cursed. This chapter delves into the infernal art of measurement, uncovering the hidden laws that govern how data can be named, ranked, counted, or quantified. Prepare yourself—for to wield statistics is to practice a kind of taxonomy, yes  ... but one written in the ink of madness, precision, and cruelty.

\normalfont

\section{A Practical Problem}

Consider the complete craniometric dataset provided by  \textcite{Thomson1905}, available in the file \R{Thomson\_Randall-MacIver\_1905.csv},\footnote{The data file can be obtained at this book's GitHub repository: \url{https://github.com/statistical-grimoire/book/blob/main/data/Egyptian-skulls}} a ``small'' excerpt of which is displayed in Table \ref{tab:skulls_full}. The file contains a wide range of craniometric measurements along with other useful, and sometimes missing, contextual information, such as the estimated date range for each skull, the ruling dynasty at the time, and the archaeological site of origin. 

\input{tables/ch-4/skulls_full}

All totalled, there are 23 separate columns of information each with close to 1000 or more values to conduct an analyses with. This raises a couple of important questions:

\begin{enumerate}
    \item What exactly do we mean by ``analyses'' in this context?
    \item Given the sheer number of distinct values, how can we discuss this data in a practical and meaningful way?
\end{enumerate}

Listing the complete set of values each time we want to reference the data would be wildly impractical. And even if we were absurdly committed to doing so, it is safe to say that our meagre primate brains simply are not equipped to juggle that much information at once. What we are after then are clear, compact, and accurate descriptions of the data that still capture its essential features. Put another way, we need to distil the data's chaos into something intelligible. That is the essence of ``conducting'' an analysis and, while this may seem a hopeless task given the sheer volume of data, there is often a surprisingly large amount of order buried within this seeming chaos.

\section{Descriptive and Inferential Analyses}

The analysis of data is typically driven by two main objectives. The first is descriptive: to summarize the data in ways that are intuitive and meaningful. Perhaps unsurprisingly, this is commonly referred to as a \gls{descriptive analysis}. The second objective is inferential: to use those summaries to make conclusions that reach beyond the data at hand. These conclusions are generally assumed to have some form of practical relevance\footnote{While practical relevance should be a requirement for any inferential analysis, many such analyses are performed more out of tradition than genuine purpose. This isn't cynicism—just the voice of experience, tinged with a bit of jadedness.}—for example, perhaps they help to answer a key research question. This process is known as \gls{inferential analysis}, and it always builds upon descriptive analysis as a necessary foundation.

In many respects a \textit{descriptive analysis} should be a purely empirical endeavour. To the best of the analyst’s ability, it seeks to answer a simple question: what can be said with certainty about this data? This often involves computing summary statistics that characterize the dataset as a whole. For example, calculating familiar measures such as the mode, median, and mean, or visualizing the distribution using graphs like histograms, are all methods that tell us something about which values are most commonly observed in the data set and how the values as a whole are distributed.

\textit{Inferential analysis} goes a step further by introducing reasonable assumptions that allow us (the analyst) to make predictions or generalizations that extend beyond the data at hand. In most cases, we are not interested in the dataset for its own sake—we care about what it represents. That is, we want to know what can it tell us about a broader population, what trends might it reveal about an underlying system, what future outcomes might it help us predict? Statistical methods that allow us to extrapolate in this respect are inferential in nature.

\section{Data}

The word data has appeared frequently throughout this book, often without much reflection as to what it actually means. Given that data is the central subject of both \textit{descriptive} and \textit{inferential} analysis, it is perhaps worth taking a moment to clarify. At its core, \gls{data} refers to a collection of observations about \textit{something}. The singular form, \gls{datum}, refers to just one of those observations. The ``something'' in question is usually the phenomenon the researcher is investigating—this could be the number of cells in a slice of brain tissue, the rate of deaths per capita, how quickly participants learn a behavioural response; or any number of other things that can be measured or classified in some way. 

Before going further, it’s worth drawing a distinction between what we will refer to as \textit{statistical data}—the kind typically used in research and analysis (e.g., see Table \ref{tab:msleep} and Table \ref{tab:skulls_full})—and the kind of data used to train machine learning models (e.g., pictures of cats, playlists of Eurodance hits, or whatever else the algorithm gods demand). In the latter case, what is being fed to the model is perhaps more akin to collections of stimuli than it is data in the traditional statistical sense of the term. That said, in machine learning contexts, the terms \textit{data} and \textit{stimuli} are often used interchangeably. When this book refers to ``data'', you can assume it means \textit{statistical data}.\footnote{Yes, I’m aware I haven’t defined the term ``statistic'' yet. But some knowledge comes at a price—and you haven’t bled nearly enough.}

\section{Variables}

Examining Table \ref{tab:skulls_full}, we can see that each row corresponds to a single skull examined by \textcite{Thomson1905}. Each column captures a different type of information recorded for that skull. Some columns contain categorical details—such as the ruling dynasty at the time of burial, the archaeological site where the skull was found, or the presumed sex of the individual—while others include numeric measurements, like the glabello-occipital length (gol), ophryo-occipital length (ool), and basi-bregmatic height (bbh), just to name a few.\footnote{View the data file's \href{https://github.com/statistical-grimoire/book/blob/main/data/Egyptian-skulls/README.md}{README} document for the complete listing.}

Each column in a dataset represents what we call a \gls{variable}—a single characteristic or property that can differ (i.e., \textit{vary}) across the observations. It is worth noting that this use of the term ``variable'' is slightly different from how it is often used in something like algebra, which is probably the most familiar context in which the term appears. In algebra, a variable is a symbol that stands for an unknown value or set of values (hence the classic phrase ``solve for $x$'', with $x$ being the variable). Still, the two meanings have an underlying connection because, in both cases, we are referring to something—be it a symbol, label, or phrase—that can represent different values. For example, in Table \ref{tab:skulls_full} \textit{sex} is a variable that (from \citeauthor{Thomson1905}'s perspective) has two possible values: ``male'' and ``female.''  Cranial capacity (\textit{cc}) is also a variable, but it is a variable which can take on a theoretically infinite amount of possibilities that extend anywhere from 0 to infinity in the positive direction.\footnote{This is not to suggest that Godzilla-sized skulls are in any way feasible. An asymptote lurks somewhere along the continuum — and long before we reach kaiju level proportions, the laws of physics (and the poor creature’s neck) would surely intervene.}

The way you conduct a descriptive or inferential analysis hinges on the nature of your variables. For instance, it makes little sense to compute the mean of categorical traits such as eye colour, biological sex, or whether a plant is alive or dead. While this may seem self-evident, these types of variables are often represented numerically in data files. For example, ``Alive'' might be coded as 1 and ``Dead'' might be coded as 0, giving the illusion that arithmetic operations are appropriate. But calculating a mean assumes the data have specific numerical properties: namely, that the values lie on a scale where addition and division are meaningful. When these conditions are not met, the result is not just meaningless—it is misleading. For example, if you have 20 plants that are alive and 30 that are dead, calculating the mean would yield an ``aliveness'' score of 0.4. But what does that actually tell you? That the average plant is 40\% alive? As we will see, the mean is intended to reflect the value most typical of the data. But what exactly is ``typical'' about 0.4 when, under our coding scheme, the only valid values are 0 (dead) and 1 (alive)? No plant in the dataset is 40\% alive. The absurdity of this result lays bare the danger of treating categorical variables as if they were genuinely numerical. Just because something is \textit{represented} by a number does not mean it \textit{is} a number.

This issue strikes at the very core of what it means to measure something. Once a research question is identified, what needs to be measured often feels self-evident—duration, height, topography, severity, intensity, hardness, rate, and so on. But how to measure it is an entirely different matter. Suppose we want to assess the height of 100 people. One approach is straightforward: use a tape measure and record each individual’s height in metres. Alternatively, we could assign rankings—giving the tallest person a score of 100 and the shortest a score 1. A third option would be to sort them into broad categories: short, medium, and tall. Or we might simply ask them, via questionnaire, ``How tall are you in metres?'' While one of these methods clearly rises above the others in terms of scientific precision, each method produces its own kind of height ``measurement''.\footnote{To show how flexible measurement can be, in Canada, distance is commonly measured in units of time. For example: ``Eh bud, d'ya know how far Timmies is?'' `Oh, bout five minutes. Just make a larry, it's kitty-corner from the rink.' ``Thanks eh.''} And therein lies the deeper problem: not every measurement is created equal.

\section{Measurement and The Problem of Measurability}

Prior to the late 1940s, scientific measurement was primarily understood as the assignment of numbers to real-world magnitudes—quantities that were assumed to exist independently of the observer. The central idea being that mathematical relationships could meaningfully represent relationships among physical objects or phenomena. However, a philosophical dilemma began to take shape as the field of Psychology sought to align itself with the standards of the natural sciences. There was heated debate about whether mathematical relations could validly capture the complexities of the human mind. At the heart of this controversy was a deceptively simple question: Is it possible to measure human sensation? \parencite[p. 677]{Stevens1946}.

To get a sense of the problem being grappled with, suppose you ask participants in a study to rate their happiness on a 11-point scale, where 0 represents the absence of any happiness and 10 represents the happiest they could conceivably be. For simplicity, imagine you only have two participants—one selects a 3, the other a 5. A common research practice is to compute the scores mean, which in this case would be 4 (see equation \ref{eq:sens_1}). 

\begin{equation}
\frac{3 + 5}{2} = \frac{8}{2} = 4
\label{eq:sens_1}
\end{equation}

\noindent
This seems straightforward enough. The average happiness level across these two people is 4. However, there is a potential problem lurking here: the ``psychological distance'' between the numbers on the scale may not be consistent across individuals. What one person considers a 5, another might interpret as a 4, or as a 6, or as a 7, or as a 8.4, or a 2.66, or some other value. That becomes an issue when we calculate a mean because the process of adding the values in the numerator assumes these values have a meaning independent of the person. For instance, if instead the participants had reported 2 and 6 we would similarly arrive at 8 in the numerator (see equation \ref{eq:sens_2}).

\begin{equation}
\frac{2 + 6}{2} = \frac{8}{2} = 4
\label{eq:sens_2}
\end{equation}

\noindent
However, we have no compelling reason to assume that a mathematical equality such as $(3 + 5) = (2 + 6)$ should hold in this context (see \ref{eq:sens_3}), because these numbers reflect \textit{subjective} judgments—not objective quantities grounded in a standardized unit of measurement. Is it mathematically true that both $(3 + 5) = 8$ and $(2 + 6) = 8$? Yes, arithmetically. But in the realm of subjective ratings, such an equality only holds if participants are interpreting the scale in a comparable way. While that is possible, it is far from guaranteed given the vast differences in individual physiology and lived experience people have.

\begin{equation}
(3 + 5) \stackrel{?}{=} (2 + 6) \stackrel{?}{=} 8
\label{eq:sens_3}
\end{equation}

\noindent
And the problems do not end there. More fundamentally, there is no objective means of verifying the accuracy—or even the honesty—of any subjective report. We are left to trust that participants are both willing and able to faithfully describe their internal states. This issue, often referred to as the \textit{problem of introspection}, has haunted Psychology since its inception, tracing back to Wilhelm Wundt’s 19th-century laboratory, where the first systematic efforts to understand ``minds'' began.\footnote{One could argue that this problem traces back even earlier, to the foundational work of Ernst Heinrich Weber and Gustav Fechner in psychophysics—research that Wundt deeply admired and which heavily influenced his own.}

None of this is to suggest that subjective assessments should be dismissed outright as pseudoscience and you would be hard pressed to find anyone in the modern day dismissing these types of measures out of hand. As \textcite{Labovitz1967} contends, there may be some practical value—however impure—in treating such ratings as more numerical than they truly are. Despite their crude, unstable, and potentially erroneous nature, these measures may still contain just enough precision to tease some signal from the noise. By analogy, the literal sound an engine makes is not what powers a vehicle, but a skilled mechanic can sometimes diagnose a problem from the sound alone. Subjective assessments may be similar in this respect. Introspection is, without doubt, a murky cauldron—but an obsession with methodological purity does risk sacrificing potentially useful data on the altar of perfectionism. We ought not discard what might yield insight simply because it falls short of an ideal.

\section{Scales of Measurement}

The most influential attempt to resolve the problem of measurement came from \textcite{Stevens1946}, who defined measurement as the ``assignment of numerals to objects or events according to rule'' (p. 677), a view that aligned with the operationalist philosophy dominant at the time. Stevens proposed that measurement could be classified into four distinct scales—nominal, ordinal, interval, and ratio—each defined by the specific rules used to assign numbers. These rules, in turn, determine which mathematical operations are meaningful for a given type of measurement. The four scales can be loosely conceptualized as a progression from less to more quantitatively meaningful, with nominal scales representing categories and ratio scales representing fully numeric measurements that support the full range of arithmetic operations.

\subsection{Nominal Scales}

One of the most basic properties of numbers is that they are distinct from every other number: for example, $1 \neq 2$, $2 \neq 3$, $3 \neq \sqrt{3}$, and so on. Likewise, identical numbers are treated as equivalent: $1 = 1$, $2 = 2$, $\sqrt{3} = \sqrt{3}$, etc. Nominal scales preserve this property of distinctness and equivalence that numbers have. In other words, they allow us to determine whether two values refer to the same category or not, but they do \textit{not} carry any information about order, magnitude, or arithmetic relationships. For example, if we define a variable for handedness—assigning 0 for ambidextrous, 1 for left-handed, and 2 for right-handed—we are simply labelling three distinct categories. The numbers here are symbolic: $2$ does not imply that right-handedness is ``greater'' than left-handedness, only that $1 \neq 2 \neq 0$.

Mathematics aside, nominal measurement scales are fundamentally about categorizing observations into mutually exclusive\footnote{\textit{Mutually exclusive} means that each observation can belong to only one category. You cannot, for instance, be both right-handed and ambidextrous.} unordered groups. The numbers are just convenient labels. Common examples include binary responses like yes or no, taste qualities such as sweet, sour, salty, bitter, and savoury, or biological traits like feeding strategy (e.g., herbivore, carnivore, omnivore, detritivore), disease presence (e.g., infected vs. not infected), or treatment group (e.g., placebo, drug A, drug B). What matters is not the number itself, but the category it stands in for. 

At the risk of undermining what was just said, in many cases, researchers do not actually bother coding nominal categories as numbers at all. For example, Table \ref{tab:skulls_full} stores the nominal variables (dynasty, location, sex) as plain text. Modern computers handle character strings efficiently, and it is often easier to interpret variable levels when they are stored in a human-readable format. Of course, exceptions exist—especially in contexts like regression analysis, where categorical variables must be converted into numerical representations to be included in the model.

\subsection{Ordinal Scales}

Ordinal scales share the properties of distinctness and equivalence found in nominal scales, but they also introduce the crucial property of order. That is, the numbers can be arranged meaningfully along a ranked continuum: 1 is greater than 0, 2 is greater than 1, 3 is less than 4, and so on. In other words, ordinal scales impose a logical sequence—such as $0 < 1 < 2 < 3 < 4$—on the categories they represent. When coding variables that have an inherent order, the numerical values used should reflect that ordering.

A classic example is letter grades. A grade of $A$ reflects a higher level of academic performance than a $B$, which in turn reflects higher performance than a $C$, and so forth. These categories are often translated into grade point values—e.g., $A = 4.0$, $B = 3.0$, $C = 2.0$—which makes the ranking explicit: $4.0 > 3.0 > 2.0$. However, this is where the usefulness of the numbers stops. We cannot meaningfully say that an $A$ is ``twice as good'' as a $C$, or that the difference between a $B$ and a $C$ is the same as the difference between an $A$ and a $B$. This is because the criteria for assigning these grades differ across courses, disciplines, and institutions. The numeric labels indicate order, but not magnitude or difference.

Other examples of ordinal scales include developmental stages in biology (e.g., larva $\rightarrow$ pupa $\rightarrow$ adult), where the stages follow a clear order but the differences between them are not necessarily equal in duration or complexity. In chemistry and safety contexts, hazard levels (e.g., flammable $\rightarrow$ highly flammable $\rightarrow$ extremely flammable) represent increasing danger, but again without uniform steps. In astronomy, seeing conditions are rated subjectively as ``poor,'' ``fair,'' ``good,'' and so on—ordered categories that describe atmospheric clarity without precise measurement. Similarly, the Fujita Scale for tornadoes ranks storm intensity from F0 to F5 based on observed damage, providing an ordered but not evenly spaced classification.

% ADD IN OTHER EXAMPLES

\subsection{Interval Scales}

The interval scale is the first scale in which measurements are meaningfully numerical, supporting standard mathematical operations with minimal risk of misapplication. Like ordinal scales, interval scales preserve both distinctness (different numbers represent different things) and order (larger numbers represent greater amounts). But interval scales go a step further by allowing meaningful statements about the differences between values—because the units along the scale are empirically equal.

Take, for example, the span of time between certain historical events. The difference between the years 1347 and 1014 is the same as the difference between 1666 and 1333: in both cases, exactly 333 years separate the two points. These differences are equivalent because a year is a standardized, empirically defined unit—it corresponds to the time it takes the Earth to complete one full orbit around the Sun, or more precisely, the time between two vernal equinoxes (when the Sun crosses the equator heading north and a blood sacrifice is demanded). Crucially, this unit does not change depending on when it is measured. A year is a year, whether you’re counting from the fall of Rome or the end of the world.\footnote{A small caveat: we are treating the empirical unit of a year as if it were perfectly constant, when in fact it fluctuates by fractions of a second due to gravitational interactions, axial wobble, and orbital quirks. These variations are imperceptible to humans and rarely matter in practice—but over time, the errors accumulate. This is, of course, the reason leap years exist: to reconcile our tidy calendar with the untidy behaviour of the cosmos.}

Often, when we measure something to be a value of zero, we are not just assigning a number—we are declaring the absence of the thing itself. For instance, a height of 0 metres implies no person. A scale reading 0 kg suggests nothing is being weighed. However, interval scales eschew this. On interval scales a value of zero does not represent the absence of the thing being measured. For example, if we measure time in years, the year 0 does not indicate the absence of time—it is simply a reference point.\footnote{Casually referring to year 0 is a bit of a historical no-no. In the calendar used by most historians (the Gregorian calendar), there is no year 0—time jumps straight from 1 BCE to 1 CE with no pause for breath. The concept of zero didn’t exist in Roman numerals, so early timekeepers just skipped it. Astronomers, being a more mathematically inclined bunch, use a system that does include a year 0—because trying to do calculations across 1 BCE/1 CE without one is annoying.} Consider temperature as another case. On the Celsius scale, 0 degrees is defined as the freezing point of water, but this does not indicate the absence of temperature. The molecules in the water are still moving—still vibrating and colliding—meaning there is still kinetic energy present. In short, zero on an interval scale is arbitrary, not absolute.\footnote{This is why the concept of absolute zero exists, it is the theoretical point at which all molecular motion stops: $−273.15^\circ C$}

This fact about zeros and interval scales has big implications for the kind of mathematics we can conduct. Interval scales allow us to talk meaningfully about the \textit{difference} between measurements. However, they do not allow us to make meaningful statements about the \textit{ratio} of two measurements. For example, we cannot say that $10^\circ$C is twice as warm as $5^\circ$C (see Equation \ref{eq:temp_ratio_1}).

\begin{equation}
\frac{10^\circ \text{C}}{5^\circ \text{C}} \neq 2
\label{eq:temp_ratio_1}
\end{equation}

\noindent
This is one of the core issues with having an arbitrary, rather than absolute, zero. A ratio such as Equation \ref{eq:temp_ratio_2}—

\begin{equation}
\frac{10}{5} = 2
\label{eq:temp_ratio_2}
\end{equation}

—implies that 10 contains two full units of whatever quantity is represented by 5. But that logic only works when zero represents the complete absence of the thing being measured.

Interestingly, while interval scales do not support ratios of values, they do support ratios of \textit{differences}. For example, if the temperature on Monday was $10^\circ$C and the temperature on Tuesday was also $10^\circ$C, the difference is 0°C—an absolute value indicating no change in temperature (i.e., $10^\circ$C − $10^\circ$C = $0^\circ$C). In this context, zero \textit{does} mean ``none of the thing''—it reflects a complete absence of temperature change. In other words, talking in terms of differences gives us an absolute zero that we can utilize in the context of ratios. 

For instance, it is perfectly valid to say that the temperature change between $10^\circ$C and $0^\circ$C is twice as large as the change between $5^\circ$C and $0^\circ$C:

\begin{equation}
\frac{10^\circ \text{C} - 0^\circ \text{C}}{5^\circ \text{C} - 0^\circ \text{C}} = 2
\label{eq:temp_ratio_3}
\end{equation}

Now admittedly, if you look at how Equation \ref{eq:temp_ratio_3} arrives at a value of 2, you might be confused—because it appears to be doing exactly what Equation \ref{eq:temp_ratio_1} said was not permissible. Step by step, the calculation proceeds as follows:

\begin{equation}
\frac{10^\circ \text{C} - 0^\circ \text{C}}{5^\circ \text{C} - 0^\circ \text{C}} = \mathbf{\frac{10^\circ \textbf{C}}{5^\circ \textbf{C}}} = \frac{10\cancel{^\circ \text{C}}}{5\cancel{^\circ \text{C}}} = 2
\label{eq:temp_ratio_4}
\end{equation}

The second step (in bold text) looks identical to Equation \ref{eq:temp_ratio_1}. But it is not the same. In Equation \ref{eq:temp_ratio_1}, the numerator and denominator represent absolute temperatures—values on an arbitrary scale where zero does not represent an absence of temperature. In contrast, in Equation \ref{eq:temp_ratio_4}, both the numerator and denominator represent temperature differences, and differences on an interval scale are meaningful because they reflect quantities with consistent units.

Unfortunately, this is a distinction that the math alone can obscure. The symbolic operations may look identical, but the interpretation depends entirely on what the numbers represent.


\begin{mdframed}[nobreak = true, style = miscFrame, frametitle = \Large\IMFellEnglish Box 4.1: The GPA Illusion]
\IMFellEnglish

Let’s take a moment to talk about something sacred: the Grade Point Average (GPA). That little number—$3.2$, $3.9$, or (gulp) $2.3$—wields tremendous power. It determines scholarships, grad school admissions, and sometimes whether your parents buy you dinner. But there’s a secret no one likes to talk about: GPA is a mathematical illusion. It’s the \textit{mean} average of grade point values ($A = 4.0$, $B = 3.0$, $C = 2.0$, etc.), which themselves are just numbers slapped onto ordinal categories. We know that an $A$ is better than a $B$, and a $B$ is better than a $C$—but is the \enquote{distance} between them truly equal? Does moving from a $B$ to an $A$ represent the same leap in achievement as going from a $D$ to a $C$?

If you’re thinking \enquote{probably not,} you’d be right. Taking the mean of ordinal data is technically a no-no because the math assumes equal spacing between the numbers—something ordinal scales don’t guarantee. It's like claiming the difference between silver and gold medals is the same as between bronze and a participation ribbon. If we were being HONEST AND FAIR, we’d use the \textit{median} average instead: it respects rank without pretending the scale is evenly spaced. But honesty doesn’t feed the machine. The \textit{median} flattens distinctions. It produces ties. It refuses to give the illusion of precision that bureaucracies crave. The \textit{mean}, in contrast, offers lovely decimals—$3.47$ vs. $3.52$—that suggest meaningful differences where none may exist. It is ideal for sorting, and thus ideal for systems that would prefer not to think too hard.

Your instructors probably know better. Most of them, anyway. But the people making the rules—the ones who decide how grades are processed—tend to prioritize convenience over correctness.\footnote{I am going to get in so much trouble for writing all this.} Why else would an entire institution choose a method so statistically indefensible? Their unofficial motto might as well be: \textit{Numerus est veritas, etiam si mendacium}—\enquote{The number is truth, even if it’s a lie.}

\end{mdframed}


% Note: you can perform any mathematical operation you'd like as long as it does not break the rules of the particular scale.

% Continuous vs discrete and %qualitative vs quantitative.


% Note: some scales can operate on more than one level.  E.g. 
% pH category (e.g., acidic, neutral, basic)
% → The pH value is quantitative, but these categories are nominal.

% Element name (e.g., hydrogen, carbon, oxygen)
% → The atomic number is quantitative, but the names themselves are nominal.



% Given what has been said so far, it is hopefully understandable that while not all data conforms to our ideals surrounding numbers and measurement there may still be a certain utility in ascribing numbers to things that are not necessarily quantifiable in the traditional sense. 

% Talk about stevens

%It is often useful to break observations up into sensible categories and perhaps even order those categories. Along these lines data is usually considered to fall into one of two camps: \textbf{qual}itative or \textbf{quant}itive.

% add in faces to allude to Janus?

% Qualitative data consists of non-numeric values or categories. 

% Add examples of qualitative data here

% Calling this type of data ``non-numeric'' signals that mathematical operations—like addition, subtraction, or division—simply do not make sense in this context. Take handedness as a basic example: a person might be left-handed, right-handed, or ambidextrous. But what would it mean to divide ``right-handedness'' by two? The question is not just unanswerable—it is nonsensical.

% The same confusion arises when we try to treat certain subjective ratings as if they behaved like physical quantities. Returning to the earlier example of happiness, what does it mean to add 2 units of happiness to a happiness rating of 1? Does that place us neatly at a 3, as though we were laying metre sticks end to end? Or do psychological realities interfere—perhaps there are diminishing returns, so that adding 2 units only nudges the total to 2.5, or even less? Is the psychological distance between a happiness rating of 1 and 2 the same as the distance between 2 and 3? Maybe as you increase happiness the distance between the levels expands? Or maybe happiness compresses as it stacks? These are the kinds of questions that remind us why treating certain kinds of data as if they obey the laws of arithmetic can be deeply misleading.

















% Talk about how something is measured (e.g., operational defintions)

% Quantitative data is data as most people conceive of it. It is data which consists of countable or numerical values.



% assigning numbers to magnitudes


%https://plato.stanford.edu/entries/measurement-science/

% Add examples of descriptive and inferential analyses.

% Samples and populations

% Add glossary entries for variables and descriptive and inferential analyses.

% Define qunatitative and qualitative.

%Include section on Random variables?

% \section{Central Tendency and Spread}

% \subsection{Types of Numeric Data}


%https://www.britannica.com/science/sone